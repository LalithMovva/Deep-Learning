{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Maze_Solver_using_Reinforcement_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTGcZvfqBMB3"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oth7YkXYBMB5"
      },
      "source": [
        "#Modelling a Maze\n",
        "def gen_maze(N):\n",
        "    \n",
        "    randRow = N\n",
        "    randCol = N\n",
        "    steps = N\n",
        "\n",
        "    i = 0\n",
        "    j = 0\n",
        "\n",
        "    mazeMap = [[0 for x in range(randCol)] for y in range(randRow)]\n",
        "    mazeMap[i][j] = 'S'\n",
        "\n",
        "    while steps != 0:\n",
        "        iORj = random.choice([True, False])\n",
        "        incORdec = random.randint(0, 5)\n",
        "        if iORj and (incORdec > 0) and i != randRow - 1 and mazeMap[i + 1][j] != 'S' and mazeMap[i + 1][j] != '.':\n",
        "            i = i + 1\n",
        "            mazeMap[i][j] = '.'\n",
        "            if steps == 1:\n",
        "                mazeMap[i][j] = 'E'\n",
        "        elif iORj == False and (incORdec > 0) and j != randCol-1 and mazeMap[i][j+1] != 'S' and mazeMap[i][j + 1] != '.':\n",
        "            j = j + 1\n",
        "            mazeMap[i][j] = '.'\n",
        "            if steps == 1:\n",
        "                mazeMap[i][j] = 'E'\n",
        "        elif iORj and (incORdec == 0) and i != 0 and mazeMap[i-1][j] != 'S' and mazeMap[i-1][j] != '.':\n",
        "            i = i - 1\n",
        "            mazeMap[i][j] = '.'\n",
        "            if steps == 1:\n",
        "                mazeMap[i][j] = 'E'\n",
        "        elif iORj == False and (incORdec == 0) and j != 0 and mazeMap[i][j-1] != 'S' and mazeMap[i][j-1] != '.':\n",
        "            j = j -1\n",
        "            mazeMap[i][j] = '.'\n",
        "            if steps == 1:\n",
        "                mazeMap[i][j] = 'E'\n",
        "        else:\n",
        "            continue\n",
        "        steps = steps - 1\n",
        "\n",
        "    ii = 0\n",
        "    jj = 0\n",
        "\n",
        "    for ii in range(0, randRow):\n",
        "        for jj in range(0, randCol):\n",
        "            iORj = random.choice([True, False])\n",
        "            if mazeMap[ii][jj] != 'S':\n",
        "                if mazeMap[ii][jj] != '.':\n",
        "                    if mazeMap[ii][jj] != 'E':\n",
        "                        if iORj:\n",
        "                            mazeMap[ii][jj] = '*'\n",
        "                        else:\n",
        "                            mazeMap[ii][jj] = '.'\n",
        "    return mazeMap\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE-5gE7OBMB7"
      },
      "source": [
        "def get_goal_indx(maze,N):\n",
        "    \n",
        "    s=0\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if maze[i][j] == 'E':\n",
        "                return s\n",
        "            s+=1\n",
        "    return -1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPJhtglJBMB8"
      },
      "source": [
        "def get_next_state(maze,N):\n",
        "    \n",
        "    indx = np.zeros([N,N])    \n",
        "    s=0\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            indx[i][j]=s\n",
        "            s+=1    \n",
        "    next_state = np.zeros([N*N, 4])\n",
        "    s=0\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if(i-1<0 or maze[i-1][j] == '*'):\n",
        "                next_state[s][0] = s\n",
        "            else:\n",
        "                next_state[s][0] = indx[i-1][j]\n",
        "                \n",
        "            if(j+1>N-1 or maze[i][j+1] == '*'):\n",
        "                next_state[s][1] = s\n",
        "            else:\n",
        "                next_state[s][1] = indx[i][j+1]\n",
        "                \n",
        "            if(i+1>N-1 or maze[i+1][j] == '*'):\n",
        "                next_state[s][2] = s\n",
        "            else:\n",
        "                next_state[s][2] = indx[i+1][j]\n",
        "                \n",
        "            if(j-1<0 or maze[i][j-1] == '*'):\n",
        "                next_state[s][3] = s\n",
        "            else:\n",
        "                next_state[s][3] = indx[i][j-1]\n",
        "            \n",
        "            if(maze[i][j] == '*' or ((i-1<0 or maze[i-1][j] == '*') and (j+1>N-1 or maze[i][j+1] == '*') and (i+1>N-1 or maze[i+1][j] == '*') and (j-1<0 or maze[i][j-1] == '*'))):\n",
        "                next_state[s][0] = -1\n",
        "                next_state[s][1] = -1\n",
        "                next_state[s][2] = -1\n",
        "                next_state[s][3] = -1\n",
        "                \n",
        "            if(maze[i][j] == 'E'):\n",
        "                next_state[s][0] = s\n",
        "                next_state[s][1] = s\n",
        "                next_state[s][2] = s\n",
        "                next_state[s][3] = s\n",
        "            s+=1\n",
        "    return next_state"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xszGbaNMBMB-"
      },
      "source": [
        "def policy_eval(policy, reward, next_state,V_old, discount_factor=1.0, theta=0.00001):\n",
        "    \n",
        "    V_new = np.zeros(16)    \n",
        "    for s in range(16):\n",
        "        v = 0.0\n",
        "        for a, action_prob in list(enumerate(policy[s])):           \n",
        "            nxt = next_state[s][a]\n",
        "            if(nxt != -1):\n",
        "                v += action_prob * (reward + discount_factor * V_old[int(nxt)])            \n",
        "        V_new[s] = v      \n",
        "    \n",
        "    return np.array(V_new)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgM70iGaBMB_"
      },
      "source": [
        "def best_action(a):\n",
        "    \n",
        "    if np.array_equal(a,[0,0,0,0]) or np.array_equal(a,[1,0,0,0])or np.array_equal(a,[0,1,0,0]) or np.array_equal(a,[0,0,1,0]) or np.array_equal(a,[0,0,0,1]):\n",
        "        return np.argmax(a)\n",
        "    freq = np.zeros(4)\n",
        "    i=0\n",
        "    while i<4: \n",
        "        j=0\n",
        "        while j<4:\n",
        "            if abs(a[i]-a[j]) < 0.00001:\n",
        "                freq[i] += 1\n",
        "            j+=1\n",
        "        i+=1\n",
        "    max_indx = np.argmax(a)\n",
        "    if freq[max_indx]>2:\n",
        "        return -1\n",
        "    return np.argmax(a)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hSH7M4tBMCB"
      },
      "source": [
        "def is_deterministic(policy):\n",
        "    \n",
        "    rows = policy.shape[0]\n",
        "    cols = policy.shape[1]\n",
        "    for x in range(0, rows):\n",
        "        for y in range(0, cols):\n",
        "            if abs(policy[x,y]-0.25)<0.0001:\n",
        "                return False\n",
        "    return True \n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y5HssQqBMCC"
      },
      "source": [
        "def policy_improvement(reward, next_state, goal_indx, policy_eval_fn=policy_eval, discount_factor=1.0):\n",
        "    \n",
        "\n",
        "    def one_step_lookahead(state, V):\n",
        "        \n",
        "        A = np.zeros(4)\n",
        "        i=0\n",
        "        for a in range(4):\n",
        "            nxt = next_state[state][a]\n",
        "            if(nxt != -1):\n",
        "                A[i] += (reward + discount_factor * V[int(nxt)])\n",
        "            i = i+1\n",
        "        return A\n",
        "    \n",
        "    policy = np.ones([16, 4]) / 4    \n",
        "    policy[goal_indx] = np.zeros(4)\n",
        "    initial_policy = policy.copy()\n",
        "    \n",
        "    V_old = np.zeros(16)\n",
        "    V_new = np.zeros(16)\n",
        "    \n",
        "    k=0\n",
        "    while True:  \n",
        "        print (\"Iteration \",k,\":\")\n",
        "        policy[goal_indx] = np.zeros(4)\n",
        "        policy_old = policy.copy()\n",
        "        V_new = policy_eval_fn(initial_policy, reward, next_state, V_old)        \n",
        "        V_old = V_new.copy()\n",
        "        print(\"Cuurent Values:\")\n",
        "        print(V_new)\n",
        "        policy_stable = True\n",
        "        \n",
        "        for s in range(16):\n",
        "            \n",
        "            action_values = one_step_lookahead(s, V_new)\n",
        "            best_a = best_action(action_values)\n",
        "            \n",
        "            if (best_a == -1):\n",
        "              policy_stable = False\n",
        "            if (best_a != -1):\n",
        "\n",
        "              policy[s] = np.eye(4)[best_a]\n",
        "        \n",
        "        k+=1\n",
        "        print(\"Current Policy Probability distribution: \")\n",
        "        print(policy)\n",
        "        if np.array_equal(policy,policy_old) and k>1 and is_deterministic(policy):\n",
        "            return (policy, V_new)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnKsK2SABMCD"
      },
      "source": [
        "def value_iteration(nS,goal_indx,discount_factor = 1.0,theta = 0.0001):\n",
        "    \n",
        "    def one_step_lookahead(state, V):\n",
        "        \n",
        "        A = np.zeros(4)\n",
        "        i=0\n",
        "        for a in range(4):\n",
        "            nxt = next_state[s][a]\n",
        "            if(nxt != -1):\n",
        "                A[i] += (reward + discount_factor * V[int(nxt)])\n",
        "            i = i+1\n",
        "        return A\n",
        "    \n",
        "    V_old = np.zeros(nS)\n",
        "    V_new = np.zeros(nS)\n",
        "    while True:\n",
        "        delta = 0\n",
        "        V_old = V_new.copy()\n",
        "        for s in range(nS):\n",
        "            if s == goal_index:\n",
        "                continue\n",
        "            A = one_step_lookahead(s, V_old)\n",
        "            best_action_value = np.max(A)\n",
        "            delta = max(delta, np.abs(best_action_value - V_old[s]))\n",
        "            V_new[s] = best_action_value    \n",
        "        print(V_new)\n",
        "        if delta < theta:\n",
        "            break\n",
        "    \n",
        "    npolicy = np.zeros([nS, 4])\n",
        "    for s in range(nS):\n",
        "        A = one_step_lookahead(s, V_new)\n",
        "        best_action = np.argmax(A)\n",
        "        npolicy[s, best_action] = 1.0\n",
        "    \n",
        "    return npolicy, V_new"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKIpu9wMBMCE"
      },
      "source": [
        "def get_path_policy(p):\n",
        "    finished = False\n",
        "    path = []\n",
        "    actions = []\n",
        "    next_square = 0\n",
        "    current_square = 0\n",
        "    while finished == False:\n",
        "        finished = True\n",
        "        for i in range(4):\n",
        "            if p[next_square][i] == 1:\n",
        "                finished = False\n",
        "                if i == 0:\n",
        "                    next_square -= N\n",
        "                    actions.append(\"up\")\n",
        "                elif i == 1:\n",
        "                    next_square += 1 \n",
        "                    actions.append(\"right\")\n",
        "                elif i == 2:\n",
        "                    next_square += N \n",
        "                    actions.append(\"bottom\")\n",
        "                else:\n",
        "                    next_square -= 1\n",
        "                    actions.append(\"left\")\n",
        "                path.append(next_square)\n",
        "    return (path,actions)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7-ZqEBaBMCF"
      },
      "source": [
        "def getMaxValueState(next_states,V):\n",
        "    max = -99999999999\n",
        "    index = 0\n",
        "    for ii in range(4):\n",
        "        c_val = V[int(next_states[ii])]\n",
        "        if c_val > max:\n",
        "            max = c_val\n",
        "            index = ii\n",
        "    return ii"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM2TEtDZBMCG"
      },
      "source": [
        "def get_path_value(V,next_state):\n",
        "    finished = False\n",
        "    path = []\n",
        "    actions = []\n",
        "    next_square = 0\n",
        "    current_square = 0\n",
        "    while finished == False:\n",
        "        finished = True\n",
        "        for i in range(4):\n",
        "            new_next_square = getMaxValueState(next_state[next_square],V)\n",
        "            if new_next_square != next_square:\n",
        "                finished = False\n",
        "                next_square = new_next_square\n",
        "                path.append(next_square)\n",
        "                if i == 0:\n",
        "                    actions.append(\"up\")\n",
        "                elif i == 1:\n",
        "                    actions.append(\"right\")\n",
        "                elif i == 2:\n",
        "                    actions.append(\"bottom\")\n",
        "                else:\n",
        "                    actions.append(\"left\")\n",
        "    return (path,actions)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "YEni1Cs5BMCH"
      },
      "source": [
        "N = 4\n",
        "maze = gen_maze(N)\n",
        "reward = -1\n",
        "discount_factor = 1.0\n",
        "goal_index = get_goal_indx(maze,N) \n",
        "next_state = list(get_next_state(maze,N))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crzB8u2nBMCI",
        "outputId": "255ce888-b259-43d0-bc4b-2a090ba44a7a"
      },
      "source": [
        "for ii in range(N):\n",
        "    print(maze[ii])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S', '.', '.', '.']\n",
            "['.', '.', '.', '.']\n",
            "['.', '.', 'E', '*']\n",
            "['*', '.', '.', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqPBpwV8BMCK",
        "outputId": "55623b36-4be6-482c-e86b-109eedee0417"
      },
      "source": [
        "#policy iteration\n",
        "start_time = time.time()\n",
        "policy, v = policy_improvement(reward, next_state , goal_index)\n",
        "exec_time = (time.time() - start_time)\n",
        "print(\"\\n\\n-------------Final Results---------\\n\\n-\")\n",
        "print(\"Policy Probability Distribution:\")\n",
        "print(policy)\n",
        "print(\"\")\n",
        "print(\"Value Function:\")\n",
        "print(v)\n",
        "print(\"\")\n",
        "path,actions = get_path_policy(policy)\n",
        "print(\"Path: \")\n",
        "print(path)\n",
        "print(\"Actions: \")\n",
        "print(actions)\n",
        "print(\"--- Running Time : %s seconds ---\" % exec_time)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration  0 :\n",
            "Cuurent Values:\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0. -1. -1. -1.]\n",
            "Current Policy Probability distribution: \n",
            "[[0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [1.   0.   0.   0.  ]\n",
            " [0.25 0.25 0.25 0.25]]\n",
            "Iteration  1 :\n",
            "Cuurent Values:\n",
            "[-2.   -2.   -2.   -2.   -2.   -2.   -1.75 -2.   -2.   -1.75  0.    0.\n",
            "  0.   -2.   -1.75 -2.  ]\n",
            "Current Policy Probability distribution: \n",
            "[[0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.   0.   0.   1.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [0.   0.   0.   1.  ]]\n",
            "Iteration  2 :\n",
            "Cuurent Values:\n",
            "[-3.     -3.     -2.9375 -3.     -3.     -2.875  -2.5    -2.9375 -2.9375\n",
            " -2.5     0.      0.      0.     -2.875  -2.4375 -2.9375]\n",
            "Current Policy Probability distribution: \n",
            "[[0.25 0.25 0.25 0.25]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   0.   1.   0.  ]\n",
            " [0.   0.   0.   1.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [0.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [0.   1.   0.   0.  ]\n",
            " [1.   0.   0.   0.  ]\n",
            " [0.   0.   0.   1.  ]]\n",
            "Iteration  3 :\n",
            "Cuurent Values:\n",
            "[-4.       -3.953125 -3.859375 -3.96875  -3.953125 -3.75     -3.1875\n",
            " -3.84375  -3.84375  -3.171875  0.        0.        0.       -3.671875\n",
            " -3.0625   -3.8125  ]\n",
            "Current Policy Probability distribution: \n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "Iteration  4 :\n",
            "Cuurent Values:\n",
            "[-4.9765625  -4.890625   -4.7421875  -4.91015625 -4.88671875 -4.56640625\n",
            " -3.86328125 -4.7109375  -4.703125   -3.81640625  0.          0.\n",
            "  0.         -4.39453125 -3.63671875 -4.625     ]\n",
            "Current Policy Probability distribution: \n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "Iteration  5 :\n",
            "Cuurent Values:\n",
            "[-5.93261719 -5.79394531 -5.6015625  -5.81835938 -5.78320312 -5.36425781\n",
            " -4.50488281 -5.54882812 -5.52734375 -4.41601562  0.          0.\n",
            "  0.         -5.06054688 -4.1640625  -5.37792969]\n",
            "Current Policy Probability distribution: \n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "\n",
            "\n",
            "-------------Final Results---------\n",
            "\n",
            "-\n",
            "Policy Probability Distribution:\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "\n",
            "Value Function:\n",
            "[-5.93261719 -5.79394531 -5.6015625  -5.81835938 -5.78320312 -5.36425781\n",
            " -4.50488281 -5.54882812 -5.52734375 -4.41601562  0.          0.\n",
            "  0.         -5.06054688 -4.1640625  -5.37792969]\n",
            "\n",
            "Path: \n",
            "[4, 5, 9, 10]\n",
            "Actions: \n",
            "['bottom', 'right', 'bottom', 'right']\n",
            "--- Running Time : 0.0428929328918457 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OORQ-6BSBMCP",
        "outputId": "6d2493c4-020b-4801-c443-bf54e85432b8"
      },
      "source": [
        "#value iteration\n",
        "start_time = time.time()\n",
        "mpolicy, v = value_iteration(N*N,goal_index)\n",
        "exec_time = (time.time() - start_time)\n",
        "print(\"\\n\\n-------------Final Results---------\\n\\n-\")\n",
        "print(\"Value Function:\")\n",
        "print(v.reshape((N,N)))\n",
        "print(\"\")\n",
        "path = []\n",
        "actions = []\n",
        "path,actions = get_path_policy(policy)\n",
        "print(\"Path: \")\n",
        "print(path)\n",
        "print(\"Actions: \")\n",
        "print(actions)\n",
        "print(\"--- Running Time : %s seconds ---\" % exec_time)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0. -1. -1. -1.]\n",
            "[-2. -2. -2. -2. -2. -2. -1. -2. -2. -1.  0.  0.  0. -2. -1. -2.]\n",
            "[-3. -3. -2. -3. -3. -2. -1. -2. -2. -1.  0.  0.  0. -2. -1. -2.]\n",
            "[-4. -3. -2. -3. -3. -2. -1. -2. -2. -1.  0.  0.  0. -2. -1. -2.]\n",
            "[-4. -3. -2. -3. -3. -2. -1. -2. -2. -1.  0.  0.  0. -2. -1. -2.]\n",
            "\n",
            "\n",
            "-------------Final Results---------\n",
            "\n",
            "-\n",
            "Value Function:\n",
            "[[-4. -3. -2. -3.]\n",
            " [-3. -2. -1. -2.]\n",
            " [-2. -1.  0.  0.]\n",
            " [ 0. -2. -1. -2.]]\n",
            "\n",
            "Path: \n",
            "[4, 5, 9, 10]\n",
            "Actions: \n",
            "['bottom', 'right', 'bottom', 'right']\n",
            "--- Running Time : 0.005521535873413086 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlaPq1NuGiSj"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}